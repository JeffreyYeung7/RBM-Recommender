{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file and append information to respective dictionaries\n",
    "movieDict = {'movieId':[],'userId':[],'rating':[]}\n",
    "with open('combined_data_1.txt', 'r') as inFile:\n",
    "    curMovie = 0\n",
    "    for line in inFile.readlines():\n",
    "        if len(line.split(\":\")) == 2:\n",
    "            curMovie = int(line.strip(':\\n'))\n",
    "        else:\n",
    "            splitLine = line.split(\",\")\n",
    "            lineVals = [int(splitLine[0].strip()), int(splitLine[1].strip())]\n",
    "            movieDict['movieId'].append(curMovie)\n",
    "            movieDict['userId'].append(lineVals[0])\n",
    "            movieDict['rating'].append(lineVals[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataframe for movieSet\n",
    "movieFrame = pd.DataFrame(movieDict)\n",
    "del movieDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1488844</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>822109</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>885013</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30878</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>823519</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>893988</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>124105</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1248029</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1842128</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2238063</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1503895</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>2207774</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2590061</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>2442</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>543865</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1209119</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>804919</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1086807</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1711859</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>372233</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1080361</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1245640</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>558634</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>2165002</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1181550</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1227322</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>427928</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>814701</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>808731</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>662870</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053734</th>\n",
       "      <td>4499</td>\n",
       "      <td>1836014</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053735</th>\n",
       "      <td>4499</td>\n",
       "      <td>1960927</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053736</th>\n",
       "      <td>4499</td>\n",
       "      <td>2385226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053737</th>\n",
       "      <td>4499</td>\n",
       "      <td>1997469</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053738</th>\n",
       "      <td>4499</td>\n",
       "      <td>811530</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053739</th>\n",
       "      <td>4499</td>\n",
       "      <td>1083336</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053740</th>\n",
       "      <td>4499</td>\n",
       "      <td>1309223</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053741</th>\n",
       "      <td>4499</td>\n",
       "      <td>604335</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053742</th>\n",
       "      <td>4499</td>\n",
       "      <td>307404</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053743</th>\n",
       "      <td>4499</td>\n",
       "      <td>1334851</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053744</th>\n",
       "      <td>4499</td>\n",
       "      <td>1061120</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053745</th>\n",
       "      <td>4499</td>\n",
       "      <td>1852040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053746</th>\n",
       "      <td>4499</td>\n",
       "      <td>268846</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053747</th>\n",
       "      <td>4499</td>\n",
       "      <td>2368103</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053748</th>\n",
       "      <td>4499</td>\n",
       "      <td>529787</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053749</th>\n",
       "      <td>4499</td>\n",
       "      <td>441248</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053750</th>\n",
       "      <td>4499</td>\n",
       "      <td>2092745</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053751</th>\n",
       "      <td>4499</td>\n",
       "      <td>555962</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053752</th>\n",
       "      <td>4499</td>\n",
       "      <td>303969</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053753</th>\n",
       "      <td>4499</td>\n",
       "      <td>654591</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053754</th>\n",
       "      <td>4499</td>\n",
       "      <td>272857</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053755</th>\n",
       "      <td>4499</td>\n",
       "      <td>185372</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053756</th>\n",
       "      <td>4499</td>\n",
       "      <td>2219917</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053757</th>\n",
       "      <td>4499</td>\n",
       "      <td>1796454</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053758</th>\n",
       "      <td>4499</td>\n",
       "      <td>2562830</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053759</th>\n",
       "      <td>4499</td>\n",
       "      <td>2591364</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053760</th>\n",
       "      <td>4499</td>\n",
       "      <td>1791000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053761</th>\n",
       "      <td>4499</td>\n",
       "      <td>512536</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053762</th>\n",
       "      <td>4499</td>\n",
       "      <td>988963</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24053763</th>\n",
       "      <td>4499</td>\n",
       "      <td>1704416</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24053764 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          movieId   userId  rating\n",
       "0               1  1488844       3\n",
       "1               1   822109       5\n",
       "2               1   885013       4\n",
       "3               1    30878       4\n",
       "4               1   823519       3\n",
       "5               1   893988       3\n",
       "6               1   124105       4\n",
       "7               1  1248029       3\n",
       "8               1  1842128       4\n",
       "9               1  2238063       3\n",
       "10              1  1503895       4\n",
       "11              1  2207774       5\n",
       "12              1  2590061       3\n",
       "13              1     2442       3\n",
       "14              1   543865       4\n",
       "15              1  1209119       4\n",
       "16              1   804919       4\n",
       "17              1  1086807       3\n",
       "18              1  1711859       4\n",
       "19              1   372233       5\n",
       "20              1  1080361       3\n",
       "21              1  1245640       3\n",
       "22              1   558634       4\n",
       "23              1  2165002       4\n",
       "24              1  1181550       3\n",
       "25              1  1227322       4\n",
       "26              1   427928       4\n",
       "27              1   814701       5\n",
       "28              1   808731       4\n",
       "29              1   662870       5\n",
       "...           ...      ...     ...\n",
       "24053734     4499  1836014       3\n",
       "24053735     4499  1960927       1\n",
       "24053736     4499  2385226       1\n",
       "24053737     4499  1997469       2\n",
       "24053738     4499   811530       4\n",
       "24053739     4499  1083336       5\n",
       "24053740     4499  1309223       1\n",
       "24053741     4499   604335       4\n",
       "24053742     4499   307404       2\n",
       "24053743     4499  1334851       3\n",
       "24053744     4499  1061120       3\n",
       "24053745     4499  1852040       1\n",
       "24053746     4499   268846       4\n",
       "24053747     4499  2368103       2\n",
       "24053748     4499   529787       4\n",
       "24053749     4499   441248       4\n",
       "24053750     4499  2092745       5\n",
       "24053751     4499   555962       5\n",
       "24053752     4499   303969       2\n",
       "24053753     4499   654591       3\n",
       "24053754     4499   272857       4\n",
       "24053755     4499   185372       1\n",
       "24053756     4499  2219917       3\n",
       "24053757     4499  1796454       1\n",
       "24053758     4499  2562830       4\n",
       "24053759     4499  2591364       2\n",
       "24053760     4499  1791000       2\n",
       "24053761     4499   512536       5\n",
       "24053762     4499   988963       3\n",
       "24053763     4499  1704416       3\n",
       "\n",
       "[24053764 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD, SVDpp\n",
    "from surprise.prediction_algorithms import BaselineOnly\n",
    "from surprise.model_selection import train_test_split, KFold\n",
    "import surprise.accuracy as accuracy\n",
    "import time\n",
    "\n",
    "# Gaurantees all folds are equivalent\n",
    "kf = KFold(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import into new loc in scikit\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(movieFrame[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "_, testing = train_test_split(data, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9000  0.9000  0.9007  0.9005  0.9008  0.9004  0.0003  \n",
      "Fit time          930.54  965.23  948.88  956.08  945.77  949.30  11.53   \n",
      "Test time         69.06   60.97   73.53   56.09   65.58   65.05   6.09    \n",
      "Time Elapsed [SVD]: 5313.096236944199\n"
     ]
    }
   ],
   "source": [
    "# SVD algorithm\n",
    "algoSVD = SVD()\n",
    "\n",
    "# start\n",
    "tS = time.time()\n",
    "\n",
    "# train on training set\n",
    "resSVD = cross_validate(algoSVD, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "\n",
    "# measure overall time\n",
    "tE = time.time()\n",
    "print(\"Time Elapsed [SVD]: {}\".format(tE-tS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD++ would generally perform the best, but with a settling time of 2 hours for 1M entries, it's realistically impossible to run this on even one part of the Neflix data so that it can be ran multiple times within the span of the project. Therefore, we test it only on 10% of the data and evaluate it on the same 30% used for the other sets. We should be careful to compare the performance to other values because even though the solution space is the same, performance obviously takes a hit as not much data is there to support it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " processing epoch 0\n",
      " processing epoch 1\n",
      " processing epoch 2\n",
      " processing epoch 3\n",
      " processing epoch 4\n",
      " processing epoch 5\n",
      " processing epoch 6\n",
      " processing epoch 7\n",
      " processing epoch 8\n",
      " processing epoch 9\n",
      " processing epoch 10\n",
      " processing epoch 11\n",
      " processing epoch 12\n",
      " processing epoch 13\n",
      " processing epoch 14\n",
      " processing epoch 15\n",
      " processing epoch 16\n",
      " processing epoch 17\n",
      " processing epoch 18\n",
      " processing epoch 19\n",
      "Time Elapsed [SVD++]: 549.9810678958893\n"
     ]
    }
   ],
   "source": [
    "\"\"\"SVD++ is MUCH more computationally intensive than the biased SVD\n",
    "    implementation and scales up on the order of >O(N^3)! As a result,\n",
    "    we only take 10% of our dataset in order to meet the constraints\n",
    "    of the project. (Runtime generally is around 2 HRS FOR 1MIL ENTRIES!)\n",
    "    Not possible within time constraint!!!\"\"\"\n",
    "#split [Yes this is very little, but it's mostly done as an example]\n",
    "trainingSVDpp, _ = train_test_split(data, test_size=.90)\n",
    "\n",
    "# SVD++ algorithm\n",
    "algo2 = SVDpp(verbose=True)\n",
    "\n",
    "# start\n",
    "tS = time.time()\n",
    "\n",
    "# train on training set\n",
    "resSVDpp = algo2.fit(trainingSVDpp)\n",
    "\n",
    "# measure overall time\n",
    "tE = time.time()\n",
    "print(\"Time Elapsed [SVD++]: {}\".format(tE-tS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Evaluating RMSE of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9329  0.9330  0.9324  0.9325  0.9333  0.9328  0.0003  \n",
      "Fit time          92.88   102.66  103.08  101.77  106.83  101.44  4.62    \n",
      "Test time         60.14   58.09   59.15   59.09   52.84   57.86   2.59    \n",
      "Time Elapsed [Baseline]: 1044.3228101730347\n"
     ]
    }
   ],
   "source": [
    "# baseline algorithm\n",
    "algo3 = BaselineOnly()\n",
    "\n",
    "# start\n",
    "tS = time.time()\n",
    "\n",
    "# train on training set\n",
    "resBASE = cross_validate(algo3, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "\n",
    "# measure overall time\n",
    "tE = time.time()\n",
    "print(\"Time Elapsed [Baseline]: {}\".format(tE-tS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7888\n",
      "RMSE: 0.9382\n",
      "RMSE: 0.9222\n"
     ]
    }
   ],
   "source": [
    "# compute RMSE using any algorithm on testing dataset\n",
    "predictions = algoSVD.test(testing)\n",
    "SVDacc = accuracy.rmse(predictions)\n",
    "predictions = algo2.test(testing)\n",
    "SVDppacc = accuracy.rmse(predictions)\n",
    "predictions = algo3.test(testing)\n",
    "BASEacc = accuracy.rmse(predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SlopeOne on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9307  0.9309  0.9310  0.9309  0.9300  0.9307  0.0003  \n",
      "Fit time          132.39  136.86  131.75  138.27  126.13  133.08  4.28    \n",
      "Test time         494.14  480.06  483.93  467.03  465.15  478.06  10.82   \n",
      "Time Elapsed [SlopeOne]: 3294.1948626041412\n"
     ]
    }
   ],
   "source": [
    "from surprise.prediction_algorithms import SlopeOne\n",
    "\n",
    "# slope one algorithm\n",
    "algoSO = SlopeOne()\n",
    "\n",
    "# start\n",
    "tS = time.time()\n",
    "\n",
    "# train on training set\n",
    "resKNN = cross_validate(algoKNN, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "\n",
    "# measure overall time\n",
    "tE = time.time()\n",
    "print(\"Time Elapsed [SlopeOne]: {}\".format(tE-tS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9074\n"
     ]
    }
   ],
   "source": [
    "predictions = algoSO.test(testing)\n",
    "SOacc = accuracy.rmse(predictions) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At this point, we just try evaluating everything on a tiny subset given that a naive algorithm like KNN would obviously generate a similarity matrix far too large to store with more than 50k users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the first 10 movies, there are 19519 unique users and 20352 entries\n"
     ]
    }
   ],
   "source": [
    "movieMaxCount = 10\n",
    "print(\"In the first {} movies, there are {} unique users and {} entries\".format(movieMaxCount,\n",
    "        len(movieFrame[movieFrame['movieId'] <= movieMaxCount].userId.unique()), \n",
    "        movieFrame[movieFrame['movieId'] <= movieMaxCount].shape[0]))\n",
    "newDataSet = movieFrame[movieFrame['movieId'] <= movieMaxCount]\n",
    "\n",
    "# Now proceed to perform predictions based on smaller dataset\n",
    "dataSmall = Dataset.load_from_df(newDataSet[['userId', 'movieId', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.2747  1.3056  1.2968  1.3010  1.2908  1.2938  0.0107  \n",
      "Fit time          17.08   17.59   17.94   17.87   17.11   17.52   0.36    \n",
      "Test time         0.40    0.45    0.39    0.51    0.40    0.43    0.04    \n",
      "Time Elapsed [KNN-Pearson-NoBaseLine]: 89.82383394241333\n"
     ]
    }
   ],
   "source": [
    "# similarity algorithm\n",
    "sim_options = {'name': 'pearson_baseline', 'shrinkage': 0}  # shrinkage=0 => no using baseline means to improve acc\n",
    "algoKNNSmall = KNNBasic(sim_options=sim_options, verbose = True)\n",
    "\n",
    "# start\n",
    "tS = time.time()\n",
    "\n",
    "# train on training set\n",
    "resKNN = cross_validate(algoKNN, dataSmall, measures=['RMSE'], cv=5, verbose=True)\n",
    "\n",
    "# measure overall time\n",
    "tE = time.time()\n",
    "print(\"Time Elapsed [KNN-Pearson-NoBaseLine]: {}\".format(tE-tS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And we measure the results compared to the other algorithms as well. This time it's comparable as all will be using the same small dataset with cross-validation present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.2801  1.2721  1.2827  1.2656  1.2508  1.2703  0.0114  \n",
      "Fit time          0.74    0.74    0.74    0.75    0.74    0.74    0.01    \n",
      "Test time         0.02    0.02    0.02    0.02    0.02    0.02    0.00    \n",
      "Time Elapsed [SVD]: 3.8925845623016357\n"
     ]
    }
   ],
   "source": [
    "# SVD algorithm\n",
    "algoSVDsm = SVD()\n",
    "\n",
    "# start\n",
    "tS = time.time()\n",
    "\n",
    "# train on training set\n",
    "resSVDsm = cross_validate(algoSVDsm, dataSmall, measures=['RMSE'], cv=5, verbose=True)\n",
    "\n",
    "# measure overall time\n",
    "tE = time.time()\n",
    "print(\"Time Elapsed [SVD]: {}\".format(tE-tS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVDpp on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.3198  1.2757  1.3125  1.2896  1.2851  1.2966  0.0168  \n",
      "Fit time          1.17    1.20    1.20    1.17    1.17    1.18    0.02    \n",
      "Test time         0.02    0.02    0.02    0.02    0.02    0.02    0.00    \n",
      "Time Elapsed [SVD++]: 6.113745450973511\n"
     ]
    }
   ],
   "source": [
    "\"\"\"SVD++ is MUCH more computationally intensive than the biased SVD\n",
    "    implementation and scales up on the order of >O(N^3)! As a result,\n",
    "    we only take 10% of our dataset in order to meet the constraints\n",
    "    of the project. (Runtime generally is around 2 HRS FOR 1MIL ENTRIES!)\n",
    "    Not possible within time constraint!!!\"\"\"\n",
    "# SVD++ algorithm\n",
    "algo2sm = SVDpp()\n",
    "\n",
    "# start\n",
    "tS = time.time()\n",
    "\n",
    "# train on training set\n",
    "resSVDppsm = cross_validate(algo2sm, dataSmall, measures=['RMSE'], cv=5, verbose=True)\n",
    "\n",
    "# measure overall time\n",
    "tE = time.time()\n",
    "print(\"Time Elapsed [SVD++]: {}\".format(tE-tS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SlopeOne on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.3116  1.3011  1.3100  1.3107  1.3022  1.3071  0.0045  \n",
      "Fit time          0.10    0.09    0.10    0.10    0.10    0.10    0.00    \n",
      "Test time         0.02    0.02    0.02    0.02    0.02    0.02    0.00    \n",
      "Time Elapsed [SlopeOne]: 5.866800785064697\n"
     ]
    }
   ],
   "source": [
    "from surprise.prediction_algorithms import SlopeOne\n",
    "\n",
    "# slope one algorithm\n",
    "algoSOsm = SlopeOne()\n",
    "\n",
    "# start\n",
    "tS = time.time()\n",
    "\n",
    "# train on training set\n",
    "resSOsm = cross_validate(algoSOsm, dataSmall, measures=['RMSE'], cv=5, verbose=True)\n",
    "\n",
    "# measure overall time\n",
    "tE = time.time()\n",
    "print(\"Time Elapsed [SlopeOne]: {}\".format(tE-tS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Evaluating RMSE of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.2740  1.2600  1.2795  1.2733  1.2602  1.2694  0.0079  \n",
      "Fit time          0.04    0.04    0.04    0.04    0.05    0.04    0.01    \n",
      "Test time         0.01    0.01    0.02    0.01    0.02    0.02    0.00    \n",
      "Time Elapsed [Baseline]: 0.3749959468841553\n"
     ]
    }
   ],
   "source": [
    "# baseline algorithm\n",
    "algo3sm = BaselineOnly()\n",
    "\n",
    "# start\n",
    "tS = time.time()\n",
    "\n",
    "# train on training set\n",
    "resBASEsm = cross_validate(algo3sm, dataSmall, measures=['RMSE'], cv=5, verbose=True)\n",
    "\n",
    "# measure overall time\n",
    "tE = time.time()\n",
    "print(\"Time Elapsed [Baseline]: {}\".format(tE-tS))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
